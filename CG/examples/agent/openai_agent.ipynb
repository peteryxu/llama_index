{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24103c51",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# Build your own OpenAI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {},
   "source": [
    "With the [new OpenAI API](https://openai.com/blog/function-calling-and-other-api-updates) that supports function calling, it's never been easier to build your own agent!\n",
    "\n",
    "In this notebook tutorial, we showcase how to write your own OpenAI agent in **under 50 lines of code**! It is minimal, yet feature complete (with ability to carry on a conversation and use tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {},
   "source": [
    "## Initial Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  \n",
    "\n",
    "The main thing we need is:\n",
    "1. the OpenAI API (using our own `llama_index` LLM class)\n",
    "2. a place to keep conversation history \n",
    "3. a definition for tools that our agent can use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41101795",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4985c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-agent-openai in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-agent-openai) (0.10.27)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-agent-openai) (0.1.14)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.16.2)\n",
      "Requirement already satisfied: pandas in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.6.4)\n",
      "Requirement already satisfied: anyio in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-agent-openai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-llms-openai in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-llms-openai) (0.10.27)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.2)\n",
      "Requirement already satisfied: pandas in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.6.4)\n",
      "Requirement already satisfied: anyio in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-agent-openai\n",
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61c873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (0.10.23)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.23 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.10.27)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.14)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.13)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.16.2)\n",
      "Requirement already satisfied: pandas in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.6.4)\n",
      "Requirement already satisfied: anyio in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.9.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.23->llama-index) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.23->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pxu/CODE/python/llama_index/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf",
   "metadata": {},
   "source": [
    "Let's define some very simple calculator tools for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfcfb78b-7d4f-48d9-8d4c-ffcded23e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcbd5ea-f377-44a0-a492-4568daa8b0b6",
   "metadata": {},
   "source": [
    "## Agent Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b737e6c-64eb-4ae6-a8f7-350b1953e612",
   "metadata": {},
   "source": [
    "Now, we define our agent that's capable of holding a conversation and calling tools in **under 50 lines of code**.\n",
    "\n",
    "The meat of the agent logic is in the `chat` method. At a high-level, there are 3 steps:\n",
    "1. Call OpenAI to decide which tool (if any) to call and with what arguments.\n",
    "2. Call the tool with the arguments to obtain an output\n",
    "3. Call OpenAI to synthesize a response from the conversation context and the tool output.\n",
    "\n",
    "The `reset` method simply resets the conversation context, so we can start another conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e068f7-fd24-4f74-8243-5e6e4840f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourOpenAIAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools: Sequence[BaseTool] = [],\n",
    "        llm: OpenAI = OpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "        chat_history: List[ChatMessage] = [],\n",
    "    ) -> None:\n",
    "        self._llm = llm\n",
    "        self._tools = {tool.metadata.name: tool for tool in tools}\n",
    "        self._chat_history = chat_history\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._chat_history = []\n",
    "\n",
    "    def chat(self, message: str) -> str:\n",
    "        chat_history = self._chat_history\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=message))\n",
    "        tools = [\n",
    "            tool.metadata.to_openai_tool() for _, tool in self._tools.items()\n",
    "        ]\n",
    "\n",
    "        ai_message = self._llm.chat(chat_history, tools=tools).message\n",
    "        additional_kwargs = ai_message.additional_kwargs\n",
    "        chat_history.append(ai_message)\n",
    "\n",
    "        tool_calls = ai_message.additional_kwargs.get(\"tool_calls\", None)\n",
    "        # parallel function calling is now supported\n",
    "        if tool_calls is not None:\n",
    "            for tool_call in tool_calls:\n",
    "                function_message = self._call_function(tool_call)\n",
    "                chat_history.append(function_message)\n",
    "                ai_message = self._llm.chat(chat_history).message\n",
    "                chat_history.append(ai_message)\n",
    "\n",
    "        return ai_message.content\n",
    "\n",
    "    def _call_function(self, tool_call: dict) -> ChatMessage:\n",
    "        id_ = tool_call[\"id\"]\n",
    "        function_call = tool_call[\"function\"]\n",
    "        tool = self._tools[function_call[\"name\"]]\n",
    "        output = tool(**json.loads(function_call[\"arguments\"]))\n",
    "        return ChatMessage(\n",
    "            name=function_call[\"name\"],\n",
    "            content=str(output),\n",
    "            role=\"tool\",\n",
    "            additional_kwargs={\n",
    "                \"tool_call_id\": id_,\n",
    "                \"name\": function_call[\"name\"],\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2cec5-6cc0-4814-92a1-ca0bd237528f",
   "metadata": {},
   "source": [
    "## Let's Try It Out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0463e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "print(os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "#print(os.environ)\n",
    "#os.environ['OPENAI_API_KEY'] = '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'\n",
    "#print(os.getenv('OPENAI_API_KEY'))\n",
    "#print(os.environ['AWS_ACCESS_KEY_ID'])\n",
    "#print(os.environ['OPENAI_API_KEY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08928f6e-610c-420b-8a7b-7a7042bbd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = YourOpenAIAgent(tools=[multiply_tool, add_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13f4f5d-0caf-42f0-ba3a-2c0890ed16af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f7650d-57b8-4ef4-b19d-651281ddb1be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletionMessageToolCall' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is 2123 * 215123\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mYourOpenAIAgent.chat\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_calls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m tool_calls:\n\u001b[0;32m---> 30\u001b[0m         function_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_call\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m         chat_history\u001b[38;5;241m.\u001b[39mappend(function_message)\n\u001b[1;32m     32\u001b[0m         ai_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mchat(chat_history)\u001b[38;5;241m.\u001b[39mmessage\n",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m, in \u001b[0;36mYourOpenAIAgent._call_function\u001b[0;34m(self, tool_call)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_call: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatMessage:\n\u001b[0;32m---> 38\u001b[0m     id_ \u001b[38;5;241m=\u001b[39m \u001b[43mtool_call\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     function_call \u001b[38;5;241m=\u001b[39m tool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     40\u001b[0m     tool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tools[function_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletionMessageToolCall' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "agent.chat(\"What is 2123 * 215123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d30b8-6405-4187-a9ed-6146dcc42167",
   "metadata": {},
   "source": [
    "## Our (Slightly Better) `OpenAIAgent` Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ca3fd-6711-4c0c-a853-d868dd14b484",
   "metadata": {},
   "source": [
    "We provide a (slightly better) `OpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \n",
    "\n",
    "In comparison to the simplified version above:\n",
    "* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework. \n",
    "* it supports multiple function calls per conversation turn\n",
    "* it supports streaming\n",
    "* it supports async endpoints\n",
    "* it supports callback and tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38ab3938-1138-43ea-b085-f430b42f5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d852ece7-e5a1-4368-9d59-c7014e0b5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool], llm=llm, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cbee4",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fd1cad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is (121 * 3) + 42?\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 3\n",
      "}\n",
      "Got output: 363\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 363,\n",
      "  \"b\": 42\n",
      "}\n",
      "Got output: 405\n",
      "========================\n",
      "\n",
      "(121 * 3) + 42 is equal to 405.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is (121 * 3) + 42?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "538bf32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolOutput(content='363', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 121, 'b': 3}}, raw_output=363), ToolOutput(content='405', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 363, 'b': 42}}, raw_output=405)]\n"
     ]
    }
   ],
   "source": [
    "# inspect sources\n",
    "print(response.sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33983c",
   "metadata": {},
   "source": [
    "### Async Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1fc974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is 121 * 3?\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 3\n",
      "}\n",
      "Got output: 363\n",
      "========================\n",
      "\n",
      "121 multiplied by 3 is equal to 363.\n"
     ]
    }
   ],
   "source": [
    "response = await agent.achat(\"What is 121 * 3?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae035cb",
   "metadata": {},
   "source": [
    "### Streaming Chat\n",
    "Here, every LLM response is returned as a generator. You can stream every incremental step, or only the last response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14217fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is 121 * 2? Once you have the answer, use that number to write a story about a group of mice.\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 2\n",
      "}\n",
      "Got output: 242\n",
      "========================\n",
      "\n",
      "121 multiplied by 2 is equal to 242.\n",
      "\n",
      "Once upon a time, in a small village, there was a group of mice who lived in a cozy little burrow beneath a big oak tree. The leader of the mouse group was a wise and courageous mouse named Milo. \n",
      "\n",
      "One sunny day, Milo gathered all the mice together and announced that they had discovered a new food source in the nearby fields. The mice were thrilled with the news and eagerly followed Milo as they scurried towards the fields.\n",
      "\n",
      "As they reached the fields, the mice were amazed to find an abundant supply of grains and seeds. It was a paradise for the hungry mice. They quickly started gathering the food and storing it in their burrow.\n",
      "\n",
      "With their newfound wealth of food, the mice became stronger and healthier. They no longer had to worry about going hungry. They even had enough food to share with other animals in need.\n",
      "\n",
      "Word of the generous mice spread throughout the forest, and soon, animals from far and wide came to visit the mice and share in their abundance. The mice became known as the kindest and most generous creatures in the forest.\n",
      "\n",
      "Milo, the wise leader, taught the other mice the importance of unity and sharing. He reminded them that their strength came from working together and helping others. The mice lived harmoniously with the other animals, and their burrow became a symbol of peace and cooperation.\n",
      "\n",
      "And so, the group of mice, with their unity and the blessings of the abundant food, lived happily ever after, spreading kindness and generosity to all the creatures in the forest."
     ]
    }
   ],
   "source": [
    "response = agent.stream_chat(\n",
    "    \"What is 121 * 2? Once you have the answer, use that number to write a\"\n",
    "    \" story about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "for token in response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac119f",
   "metadata": {},
   "source": [
    "### Async Streaming Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ea069f-819b-4ec1-a93c-fcbaacb362a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is 121 + 8? Once you have the answer, use that number to write a story about a group of mice.\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 8\n",
      "}\n",
      "Got output: 129\n",
      "========================\n",
      "\n",
      "121 plus 8 is equal to 129.\n",
      "\n",
      "Once upon a time, in a lush green meadow, there was a group of mice who lived in a cozy burrow beneath a tall daisy patch. The leader of the mouse group was a wise and adventurous mouse named Oliver.\n",
      "\n",
      "One sunny morning, as Oliver was exploring the meadow, he stumbled upon a hidden treasure chest buried beneath a pile of leaves. Excitedly, he called all the mice together and they gathered around the treasure chest in awe.\n",
      "\n",
      "With trembling paws, Oliver opened the chest to reveal a glittering collection of shiny jewels and sparkling gems. The mice gasped in amazement at the sight of the treasure. They couldn't believe their luck!\n",
      "\n",
      "Oliver, being the wise leader, suggested that they use the treasure to improve their lives and the lives of other creatures in the meadow. The mice agreed and decided to build a grand community center where all the animals could gather and enjoy each other's company.\n",
      "\n",
      "With their newfound wealth, the mice worked tirelessly day and night to construct the community center. They used the jewels to decorate the walls and the gems to create beautiful chandeliers that illuminated the space.\n",
      "\n",
      "Once the community center was complete, the mice invited all the animals in the meadow to a grand opening celebration. The meadow was filled with laughter, music, and the aroma of delicious food. The mice had prepared a feast for everyone to enjoy.\n",
      "\n",
      "The community center became a place of joy and unity. Animals from all walks of life came together to share stories, dance, and sing. The mice, with their generous hearts, organized workshops and activities to teach others new skills and foster a sense of togetherness.\n",
      "\n",
      "The meadow flourished with harmony and friendship, thanks to the mice and their treasure. The mice were admired and respected by all the animals for their kindness and generosity.\n",
      "\n",
      "And so, the group of mice, with their treasure and the spirit of sharing, created a haven of happiness and love in the meadow. They lived joyfully ever after, leaving a legacy of unity and compassion for generations to come."
     ]
    }
   ],
   "source": [
    "response = await agent.astream_chat(\n",
    "    \"What is 121 + 8? Once you have the answer, use that number to write a\"\n",
    "    \" story about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "async for token in response.async_response_gen():\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe399c5-6d07-4926-b701-b612efd56b30",
   "metadata": {},
   "source": [
    "### Agent with Personality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47c034-f948-4604-a8d8-828b617ea245",
   "metadata": {},
   "source": [
    "You can specify a system prompt to give the agent additional instruction or personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef36d1e-c26e-4b07-b3d0-3b7f314a45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.prompts.system import SHAKESPEARE_WRITING_ASSISTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba7fa46-1173-42f2-885c-0cc28df1cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    system_prompt=SHAKESPEARE_WRITING_ASSISTANT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4841778-7008-4b61-afcc-995b6b64e91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Hi\n",
      "Greetings, fair traveler! How may I assist thee on this fine day?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Hi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a83768-1203-4485-a346-2fa78089afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me a story\n",
      "Of course, dear friend! Allow me to weave a tale for thee in the style of Shakespeare. \n",
      "\n",
      "Once upon a time, in a land far away, there lived a valiant knight named Sir William. He was known throughout the kingdom for his bravery and noble heart. Sir William hath embarked on many quests, slaying dragons and rescuing damsels in distress.\n",
      "\n",
      "One fateful day, as Sir William rode through the enchanted forest, he came across a mysterious old man. The old man, with a long white beard and twinkling eyes, spoke in riddles and prophecies. He foretold of a great evil that would soon befall the kingdom, and only a true hero could save them all.\n",
      "\n",
      "Intrigued by the old man's words, Sir William vowed to fulfill his destiny and protect the realm. He set forth on a perilous journey, facing treacherous mountains and dark forests. Along the way, he encountered a band of misfit companions - a witty jester, a wise sorceress, and a loyal squire.\n",
      "\n",
      "Together, they faced many challenges and overcame countless obstacles. They battled fearsome beasts, solved intricate puzzles, and outwitted cunning villains. Through their trials, Sir William discovered the true meaning of courage, friendship, and sacrifice.\n",
      "\n",
      "In the final showdown, Sir William confronted the wicked sorcerer who sought to plunge the kingdom into darkness. With his sword raised high and his heart filled with determination, he engaged in a fierce battle. The clash of steel echoed through the air as the forces of good and evil collided.\n",
      "\n",
      "In the end, Sir William emerged victorious, banishing the sorcerer and restoring peace to the land. The people rejoiced, singing songs of his bravery and valor. Sir William hath become a legend, his name whispered in awe and admiration for generations to come.\n",
      "\n",
      "And so, dear friend, ends the tale of Sir William, the noble knight who hath saved the kingdom with his unwavering courage and indomitable spirit. May his story inspire thee to embark on thy own heroic journey and face thy challenges with the same fervor and determination.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me a story\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
